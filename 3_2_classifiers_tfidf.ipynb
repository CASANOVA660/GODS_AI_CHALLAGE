{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "from scipy.sparse import save_npz, load_npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_preprocessed_fill_missing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22151, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11098</td>\n",
       "      <td>post remove request member hi welcome immediat...</td>\n",
       "      <td>suicidal-thoughts-and-self-harm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>hi nmtb thank post think lot people terrify st...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7189</td>\n",
       "      <td>hello cas fair anxiety depression work lot com...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4350</td>\n",
       "      <td>hey everyone discover another mum 's sister de...</td>\n",
       "      <td>anxiety</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9749</td>\n",
       "      <td>hi everyone guess title say really .. 28 year ...</td>\n",
       "      <td>depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                       cleaned_text  \\\n",
       "0  11098  post remove request member hi welcome immediat...   \n",
       "1    116  hi nmtb thank post think lot people terrify st...   \n",
       "2   7189  hello cas fair anxiety depression work lot com...   \n",
       "3   4350  hey everyone discover another mum 's sister de...   \n",
       "4   9749  hi everyone guess title say really .. 28 year ...   \n",
       "\n",
       "                            target  \n",
       "0  suicidal-thoughts-and-self-harm  \n",
       "1                          anxiety  \n",
       "2                          anxiety  \n",
       "3                          anxiety  \n",
       "4                       depression  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = load_npz('data/train_tfidf_embeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22151, 4096)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2x4096 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 59 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.shape)\n",
    "X[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "relationship-and-family-issues     6688\n",
       "anxiety                            6652\n",
       "depression                         5836\n",
       "ptsd-and-trauma                    1819\n",
       "suicidal-thoughts-and-self-harm    1156\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Target encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "num_classes = len(label_encoder.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/test_preprocessed_fill_missing.csv')\n",
    "test_X = load_npz('data/test_tfidf_embeddings.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2462,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_preds = np.zeros(len(test))\n",
    "final_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing Fold 1/5\n"
     ]
    }
   ],
   "source": [
    "# Initialize cross-validation\n",
    "cv = ShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "accuracy_scores = []\n",
    "f1_macro_scores = []\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y_encoded)):\n",
    "    print(f\"\\nProcessing Fold {fold + 1}/5\")\n",
    "    \n",
    "    # Split data\n",
    "    X_train, X_val = X[train_idx], X[val_idx]\n",
    "    y_train, y_val = y_encoded[train_idx], y_encoded[val_idx]\n",
    "    \n",
    "    # Calculate class weights\n",
    "    classes = np.unique(y_train)\n",
    "    class_weights = compute_class_weight('balanced', classes=classes, y=y_train)\n",
    "    sample_weights = np.array([class_weights[i] for i in y_train])\n",
    "\n",
    "    # Initialize models with common parameters\n",
    "    common_tree_params = {\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': 0.05,\n",
    "        'max_depth': 8,\n",
    "        'random_state': 42\n",
    "    }\n",
    "    \n",
    "    # LightGBM\n",
    "    lgbm = LGBMClassifier(\n",
    "        **common_tree_params,\n",
    "        objective='multiclass',\n",
    "        num_class=num_classes,\n",
    "        force_col_wise=True,\n",
    "        verbose=-1,\n",
    "        device='gpu'  # Enable GPU\n",
    "    )\n",
    "    lgbm.fit(\n",
    "        X_train, y_train,\n",
    "        sample_weight=sample_weights,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        # early_stopping_rounds=10,\n",
    "        \n",
    "    )\n",
    "    \n",
    "    # XGBoost\n",
    "    xgb = XGBClassifier(\n",
    "        **common_tree_params,\n",
    "        objective='multi:softprob',\n",
    "        num_class=num_classes,\n",
    "        tree_method='hist'  # Enable GPU\n",
    "    )\n",
    "    xgb.fit(\n",
    "        X_train, y_train,\n",
    "        sample_weight=sample_weights,\n",
    "        eval_set=[(X_val, y_val)],\n",
    "        # early_stopping_rounds=10,\n",
    "        verbose=500\n",
    "    )\n",
    "    \n",
    "    # CatBoost\n",
    "    cat = CatBoostClassifier(\n",
    "        iterations=1000,\n",
    "        learning_rate=0.05,\n",
    "        depth=8,\n",
    "        l2_leaf_reg=5,\n",
    "        border_count=128,\n",
    "        loss_function='MultiClass',\n",
    "        verbose=500,\n",
    "        random_state=42,\n",
    "        task_type='GPU'  # Enable GPU\n",
    "    )\n",
    "    cat.fit(\n",
    "        X_train, y_train,\n",
    "        sample_weight=sample_weights,\n",
    "        eval_set=(X_val, y_val),\n",
    "        early_stopping_rounds=10\n",
    "    )\n",
    "\n",
    "    # Rebuild stacking ensemble WITHIN FOLD\n",
    "    base_models = [('lgbm', lgbm), ('xgb', xgb), ('cat', cat)]\n",
    "    stacker = StackingClassifier(\n",
    "        estimators=base_models,\n",
    "        final_estimator=MLPClassifier(\n",
    "            hidden_layer_sizes=(256, 128),\n",
    "            early_stopping=True,\n",
    "            learning_rate='adaptive',\n",
    "            # validation_fraction=0.1,  # Use 10% of training data for validation\n",
    "            n_iter_no_change=10,      # Stop if no improvement for 10 epochs\n",
    "            verbose=500              # Print progress\n",
    "        ),\n",
    "        stack_method='predict_proba',\n",
    "        passthrough=True\n",
    "    )\n",
    "\n",
    "    # Train with sample weights\n",
    "    print(\"Training stacking ensemble...\")\n",
    "    stacker.fit(X_train, y_train, \n",
    "                sample_weight=sample_weights)\n",
    "\n",
    "    # Generate predictions\n",
    "    y_pred = stacker.predict(X_val)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    fold_acc = accuracy_score(y_val, y_pred)\n",
    "    fold_f1 = f1_score(y_val, y_pred, average='macro')\n",
    "    \n",
    "    accuracy_scores.append(fold_acc)\n",
    "    f1_macro_scores.append(fold_f1)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} - Accuracy: {fold_acc:.4f}, F1 Macro: {fold_f1:.4f}\")\n",
    "    \n",
    "    final_preds += stacker.predict(test_X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average the final predictions\n",
    "final_preds /= cv.get_n_splits()\n",
    "\n",
    "# Determine the final predicted classes\n",
    "final_classes = np.argmax(final_preds, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
